# Full stack big picture

Fullstack describes a developer who can work on every aspect of an application from frontend to backend

## Backend Applications: 

Consists of the serverside application and surrounding technologies
- Code that runs on a server
- Interacts with databases
- Written in languages such as C, C#, C++, Java

## Frontend Applications:

Consists of the front facing User Interface and User Experience
- Code that runs on the desktop or web browser
- Typically written with some combination of HTML, CSS, and Javascript
- All frontend libraries will use the technologies listed above

## Http/Rest Overview

The frontend and backend now-a-days are two separate entities, so they must have a way of communicating with one another

As fullstack developers we will be also be exploring how both sides of our applications will be communicating

Typically the backend application running on the server will be in the form of a REST api (application programming interface)
- REST is an architecural design that helps backend developers design a uniform way to interface with the backend from the frontend

The frontend will communicate with this public or private REST API through a messaging protocol called HTTP.

Hypertext Transfer Protocol allows frontend developers to send requests to use the REST API service
- The frontend can simply request data, or send data in a number of ways
- The backend will respond with some response with any data the frontend was requesting

# Setting up our environments

## Install Java 11
## Install Git and Gitbash
## Install Eclispse Enterprise
## Install VSCode
## Install Postman

# Introduction to SDLC

Outlines the process to plan, create, test, and deploy information systems and appliations

## SDLC Follows these 7 general steps:

1. Requirements Phase
2. Analysis Phase
3. Design Phase
4. Development Phase
5. Testing Phase
6. Integration and Deployment Phase
7. Maintenance Phase

There are are two main approaches to SDLC currently:

-   Waterfall
-   Agile

# SDLC Waterfall

Waterfall is a linear approach, as you finish one stop you move onto the next, there is no going back

## Typical Timeline of Waterfall:

-   Requirements: 2-4 weeks
-   Planning: 2-4 weeks
-   Design: 1-4 months
-   Implementation: 6-12 months+
-   Testing: 6 months, but actually ongoing
-   Deployment: 1-3 weeks
-   Maintenance: lifetime of the application

## Advantages of Waterfall

-   Easy to manage workflow
-   Well suited for small teams, or short term projects, that will not require and requirement changes
-   Generally results in faster devilery of product
-   Process and results can easily documented
-   Easy to adapt to shifting teams since the steps are clearly laid out

## Disadvantages of Waterfall:

-   Very inflexible and inefficient
-   Not ideal for large teams projects
-   Testing does not begin until development is complete

# SDLC Agile

Agile is an iterative approach, go through every step of the SDLC in 2 - 4 week sprints

Agile is becoming the more widely accepted and utilized method of SDLC because of its core values

-   Individuals and Interactions over processes and tools
-   Working Software over comprehensive documentation
-   Customer collaboration over contract negotiation
-   Responding to change over following a plan

## Advantages of Agile:

-   Client colaboration is generally regarded as positive
-   Agile team cultures tend to stay more self-organized and motivated
-   Overall quality of prodices is usually higher due to the iterative approach
-   Less risk in development process due incremental nature of development

## Disadavantanges of Agile:

-   Not as useful for small development project
-   Higher costs associated with the Agile workflow
-   Development time can bloat if managed poorly, or requirements are not clear
-   Requires more experienced memebers during the planning and management of projects

# Project 1 Learning Objectives
# Project 1 Backlog

# OS Fundamentals

What is an operating System?
- Software that makes it easier for users to interact with their computer
    - It is a intermediary between the user of the computer and the computers hardware
    - In charge of executing the programs a user asks the computer to run
- The Operating System also acts as a manager to the resources available in the computer
    - Process management, what process should the cpu focus on running, and which ones should use less resources because they are in the background?
    - Storage management, where are all my files?
    - Memory management, does the CPU still need the data stored in that RAM stick? No? Lets clear that out
    - Security and Privacy, password managers, and checking for viruses

# Persistence vs Ephemeral Storage

Memory

- Registers/Caches on CPU
- Physical places to store VERY small peices of information on a CPU
    - Typically the byte address of some information in memory

- Random Access Memory (RAM)
    - Used to store information being used directly by the CPU, including data, programs, and program results
    - Ram allows for quick reads and writes
    - All data is lost when the computer is powered off
    - Relatively small in size (compared to harddrives)
    - Dynamic Random Access Memory
        - RAM that is continually refreshed in order to maintain the data
        - Used for most typical system memory because of its cheap costs
    - Static Random Access Memory
        - RAM that is retains its content until the power is lost
        - Used for memory caches because of its more expensive components

- Storage Memory
    - Harddrives/SSD's
    - Cheapest forms of storage
    - Slower than RAM
    - Data is persisted through power cycles

Why do we have operating systems?

1. Convience: Makes the computer more convient to use
2. Efficiency: Allows the systems resources to be used effiecently
3. Ability to evolve: The OS is structured in a way that permits effective development, testing, and introduction to new system functions at the same time without interferring with service
4. Throughput: The OS is constructed so that it can give the maximum number of tasks per unit time

Different Operating Systems
- Windows
    - XP
    - Vista
    - 7
    - 8
    - 10
    - 11
- MacOS
    - High Seirra
    - Mojave
    - Catalina
    - Big Sur
    - Monterey
    - Ventura
- Unix
    - MacOS
    - Linux
        - Ubuntu
        - RedHat
        - Fedora
        - Arch
# Unix

Unix is an open source family of operating systems that was developed in AT&T's Bell lab in the early 1970's,

Originally a small terminal based OS with hierarchical file system, computer processes, and device files, the Unix family is now a giant tree of hundreds of OS's including Mac OS, and Linux

The original Unix used a shell called sh, in 1989 a new shell system was created for Unix called the Bourne Again Shell aka bash, and this is the terminal that all modern Unix based systems is built upon

## Linux

Linux is probably the most well known Unix based operating system outside of MacOS

Linux was created by Linus Torvalds, with support and constant updates from the open source community

Now there are many distrubitions of Linux, popular ones include Ubuntu, RedHat, Arch and more

-   Ubuntu is a great first time Linux distrobution, which is easy to understand and pick up for beginners
-   RedHat is an enterprise distribution that is NOT open source, it has great resources and is used by many companies using linux development environments
-   Arch is a highly customizable distribution that advanced Linux users can leverage to get the EXACT computing experience that they are looking for

# UNIX File Commands

## Basic Unix Commands

To understand Linux commands you must first understand the file structure of the linux OS, Linux uses a tree like file system with the `root` directory of the system mapping to the `/` character

The `home` directory where user specific information is stored is denoted by the `~`

Another important note with the unix file structure is that everything in Unix is considered a file, even directories. This knowledge will come in handy later on

## Command Arguments and Flags

Commands can be modified with either arguments or flags

Arguments are given to a command after the command in the form of a string eg `command arg1 arg2...` Arugments are typically variables that your command is expecting to use during execution

Flags are denoted by either a `-` followed by a letter, which is the shorthand, or a `--` and the flag name which is the long hand, flags are special built in arguments for the command. Flags are options you can enable for your command

## Most important command `man`

The manual command will print to the terminal the manual for using a particular command. If you are unsure what flags or arguments a command takes, you simply type `man command`. For example, if you wished to see the manual for the copy command, you would issue the command: `man cp`

## Change Directory `cd`

The change directory command allows us to navigate to a different directory on the drive.

-   go to root directory: `cd /`
-   go to home directory: `cd` or `cd ~`
-   navigate one directory up: `cd ..`
-   navigate into the `hi` directory, which is inside the `bye` directory: `cd ./bye/hi`
-   change to the previous directory: `cd -`

## Listing Files in a directory `ls`

The list directory command allows us to see the contents of a particular directory. When given no arguments, it lists the contents of the 8 current directory.

-   `-a` flag allows you to see hidden items in the directory.
-   list the contents of the current directory: `ls`
-   list the contents of the `hi` directory: `ls hi` or `ls ./hi`

## Make a new directory `mkdir`

The make directory command allows us to create a new directory. mkdir takes an argument representing the name of the directory you wish to create. `mkdir supercooldirectory`

## Supstitute User `su` and Super User Do`sudo`

The substitute user command allows you to switch users. With no argument, this defaults to the root user, which has higher priveleges. This can be useful if you need to perform multiple commands with elevated priveleges but is generally considered to be bad practice in preference to `sudo`, for administrative logging purposes.

The `sudo` command allows you to run a particular command as the root user.

## Create a file `touch`

the touch command allows you to modify the timestamp of a file. This command is usually used to create empty files, as an empty file is created if touch is given a file name that does not exist.

## Print the contents of a file `cat`

# Unix Moving and Deleting

## Copy the contents of a file to another file `cp`, or the contents of a directory `cp -r`

copy a `hello.txt` to `goodbye.txt`: `cp hello.txt goodby.txt`

copy the `hello` directory to the `goodbye` directory: `cp -r hello goodbye`

## Move a file to `mv` or move a whole directory `mv -r`

the mv command allows you to rename, or move files to different directories

rename a `hello.txt` to `goodbye.txt`: `mv hello.txt goodbye.txt`

move `hello.txt` to the `goodbye` directory: `mv hello.txt goodbye/.`

rename the `hello` directory to `goodbye`: `mv hello goodbye`

## Delete a file at a specified location `rm` delete a directory `rm -r`

Never used the command `rm -rf .` this will essentially remove your entire file system

remove `hello.txt`: `rm hello.txt`

remove the `hello` directory: `rm -r hello`

# Modules 1 and 2
## https://linuxsurvival.com/linux-tutorial-introduction/

# Git Fundamentals

## Git is a version control system

It keeps track of every change ever made to a project during its lifetime

Provides a collaboration tool when working in groups

## Central vs Distributed Software Control

Central Software control (CSC) has the entire project stored in a central location with no copies allowed of the master file(s)

Distributed Software Control has a copy of all versions of the master file(s) locally on any machine this is pushed, pulled, and merged into a remote repository

Git is a Distributed Software Control System

# Git repository hosting platforms

Since git is a distributed Software Version control system we have local repositories that sync up with remote repositories. We need somewhere to store these remote repositories. Enter hosting platforms

There are many platforms that are available to be used, the most popular being GitLab, GitHub, BitBucket and more

The developers take changes from their local repositories and `push` them up to the remote repository where they they access all the code from another workstation, or other developers can `pull` in the changes to their local repository to look over the code, and even make more changes

## Git Initializing a repository

First and foremost you need to make sure that you have your git credentials configured so git bash can link your machine to your github account:

```
git config --global user.name gitusername
git config --global user.email gitemail@mail.com
```

Now to create your first local repository navigate, or open the gitbash in the folder/directory that you want to start the repository in

Once in the correct folder, you can type `git init` in the command line, this will create a .git directory to your current directory

This .git directory holds all the informations about our project versions and changes, and now that you have your local repository created, you can start making changes to your project and git will know everything that changes

# Git Basic Snapshotting

While developing projects, you will follow a work flow while using git. The typical flow is project files start in the `Working directory` these files need to be tracked. Files from the working directory are chosen to be added to the `Staging Area`, where we commit the file changes to the `Repository`. Lets take a deeper look at each step in this work flow.

When you make changes to the files in your working directory you have to tell git that you want these files tracked, to do this you use the `git status` command. This is useful to see what files were changed in your project, and which ones need to be added to gits tracking

`git status` shows untracked files in red, and prompts you to use the command `git add` to add these files to git tracking, if you don't want these files tracked you can always use `git remove`

Using the command `git add` will add the files to to `Staging Area`, the staging area is where we organize what we want to be commited to the repository at the time. Git gives developers to pick and choose the files they want to be be included in the staging area at any given time, however when getting started with git, it is common for people to just use `git add .` which will add all changed files from the working directory to be commited to the git repository

When you are happy with the staging area, you can make your commit, a commit is a snapshot of changes to your software, or you can think of a commit was a new "version" of your software. To make a commit to your local repository

To make this commit you will run the git command `git commit -m "Write a quick concise message about what you changed in this commit"
It is best practice to commit early and often, instead of making huge changes in every commit

# Git Working with remote repositories
Up to this point we have created a local repo, created and made changes to files, tracked files from our working directory into the staging area, and commited to our local repo. Now we want to store our repository onto a hosting platform, in our case we will use github
Navigate to github and login, find the `+` button to create a new repository, go through the steps of naming it, giving it a description and skip the step the final step since we are importing an existing repository
After clicking `Create repository` you will see a screen that will walk you through different situations, we will follow the option of pushing an existing repository from the command line

## Git Pushing to a remote repository
Back in our git bash we have already commited changes to our git repo, now we just need to link our local repository to our remote one on github
First run `git remote add origin linktoremoterepo` this will actually link local repo to the remote repo for you
Then run `git push -u origin main` this will push your entire project, and all the change history to a new branch called main, and set the origin to the head of that branch, aka where your project currently is in its history
Now you should be able to view all the files from the project on github, you can also look through the commits, the files you changed, and more all from the user interface of github

## Complete git flow
1. Make changes to files
2. `git status` check on the files that were changed (optional)
3. `git add files` or `git add .`
4. `git commit -m "quick meaningful message`
5. `git push origin/branchname` or `git push`

# Complete Introduction Sequence and Remote Push & Pull
https://learngitbranching.js.org/

# Create a repository for yourself, push a README.md file to github